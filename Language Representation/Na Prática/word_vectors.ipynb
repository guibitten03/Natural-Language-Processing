{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irev.data import Database\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Saved Finished ==================\n",
      "Train Size: 2420\n",
      "Test Size: 1513\n",
      "Val Size: 1513\n"
     ]
    }
   ],
   "source": [
    "bd = Database.Database(\n",
    "    \".local/data/amazon_review_dataset.csv\",\n",
    "    \".local/data\",\n",
    "    mode=\"init\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>190</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>[ugh, way, larg, man]</td>\n",
       "      <td>1495670400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>[super, comfi]</td>\n",
       "      <td>1506470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>202</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>[lightweight, comfort, support, happi, bought,...</td>\n",
       "      <td>1493683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>388</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>[comfort]</td>\n",
       "      <td>1526428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>233</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>[inch, extra, space, tip, big, toe, front, sho...</td>\n",
       "      <td>1490227200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating  \\\n",
       "1361      190       25       3   \n",
       "842       125       25       5   \n",
       "1453      202       13       4   \n",
       "2938      388       25       5   \n",
       "1705      233       25       5   \n",
       "\n",
       "                                                   text   timestamp  \n",
       "1361                              [ugh, way, larg, man]  1495670400  \n",
       "842                                      [super, comfi]  1506470400  \n",
       "1453  [lightweight, comfort, support, happi, bought,...  1493683200  \n",
       "2938                                          [comfort]  1526428800  \n",
       "1705  [inch, extra, space, tip, big, toe, front, sho...  1490227200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um tfidf para cada sentença\n",
    "# Criar um documento concatenando todos os tfidfs\n",
    "\n",
    "# Cria as embeddings para cada sentença\n",
    "# Cria as embeddings para cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Primeira Pergunta Dia\"\n",
    "b = \"Segunda Pergunta Dia\"\n",
    "c = \"Terceira Pergunta Dia\"\n",
    "d = \"Quarta Pergunta Dia\"\n",
    "# Preciso construir o vocabulario e o tamanho dele"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [a,b,c,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = vectorizer.fit_transform(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41988018 0.41988018 0.8046125  0.         0.         0.        ]\n",
      " [0.41988018 0.41988018 0.         0.         0.8046125  0.        ]\n",
      " [0.41988018 0.41988018 0.         0.         0.         0.8046125 ]\n",
      " [0.41988018 0.41988018 0.         0.8046125  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.toarray()) # Transformando uma matriz csr em uma matriz densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'primeira': 2,\n",
       " 'pergunta': 1,\n",
       " 'dia': 0,\n",
       " 'segunda': 4,\n",
       " 'terceira': 5,\n",
       " 'quarta': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(lista)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Primeira', 'Pergunta', 'Dia'],\n",
       " ['Segunda', 'Pergunta', 'Dia'],\n",
       " ['Terceira', 'Pergunta', 'Dia'],\n",
       " ['Quarta', 'Pergunta', 'Dia']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [text.split() for text in lista]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, window=2, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_matrix = []\n",
    "\n",
    "for text in corpus:\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        new_text.append(model.wv[word])\n",
    "    new_text = np.mean(np.array(new_text), axis=0)\n",
    "    w2v_matrix.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-5.9611327e-03,  2.0107769e-03,  3.1398963e-03,  1.8107076e-03,\n",
       "        -3.7547245e-03, -4.8984010e-03,  3.9989650e-03,  6.2414468e-03,\n",
       "        -4.7847242e-03, -5.6033209e-03,  6.5695652e-04, -4.0630880e-03,\n",
       "        -5.7956376e-03,  1.3517576e-03, -1.4170833e-03, -9.8439632e-04,\n",
       "         1.2126504e-03,  9.5056230e-04, -4.8061688e-03, -3.9058737e-03,\n",
       "         2.3438130e-04, -6.1323248e-05,  7.7663106e-03, -4.6828960e-04,\n",
       "         1.9698052e-03, -1.3859267e-03, -9.2022697e-04,  1.9867951e-04,\n",
       "        -2.5949243e-03,  3.0999156e-03,  2.7332294e-03, -4.6851826e-03,\n",
       "         1.4738790e-03, -7.0516546e-03,  5.2100333e-04,  3.3708399e-03,\n",
       "         6.9806068e-03,  1.7458359e-03,  4.8815743e-03,  4.2558866e-04,\n",
       "         2.6155666e-03, -3.1128787e-03, -8.3952798e-03, -2.3376558e-03,\n",
       "        -1.3045006e-03,  1.4606771e-03, -7.7175052e-04,  5.1859678e-03,\n",
       "         1.9318344e-03,  3.1327477e-03,  8.0135092e-04, -4.4578295e-03,\n",
       "         1.1710655e-03,  4.2766123e-03, -6.7481305e-04,  2.1219540e-03,\n",
       "         7.8110844e-03, -2.6387523e-03, -3.7423428e-03,  3.1241316e-03,\n",
       "        -5.7202129e-04,  9.4904733e-04,  1.2192720e-04, -6.9766212e-03,\n",
       "         1.9415650e-03,  3.4917258e-03,  2.5414003e-03,  6.9827709e-04,\n",
       "        -9.2623668e-04, -1.5760399e-04,  1.3668569e-03,  1.9162557e-03,\n",
       "         3.9898050e-03,  1.0125026e-03,  9.3522196e-04,  7.2269776e-04,\n",
       "        -2.9934440e-03,  3.1929871e-05,  9.2386449e-04, -2.8536674e-03,\n",
       "        -9.4694440e-04, -2.3954703e-05,  5.2901297e-03, -2.9660438e-03,\n",
       "        -1.7663408e-03, -2.9682647e-03,  3.3819801e-04, -1.7974445e-03,\n",
       "        -7.5783930e-04,  1.6539831e-03,  3.9301342e-03,  2.5172753e-03,\n",
       "        -8.4604154e-04, -3.5587039e-03,  5.5960827e-03,  4.2760777e-03,\n",
       "        -1.7195985e-03, -6.0416986e-03, -1.8823739e-03,  1.4075050e-03],\n",
       "       dtype=float32),\n",
       " array([-5.43164322e-03,  1.71440002e-03,  1.03883899e-03,  4.16886434e-03,\n",
       "         6.27757341e-04, -2.48378678e-03,  2.92088953e-03,  5.70766767e-03,\n",
       "        -3.98862315e-03, -9.03853681e-04,  2.21079987e-04, -1.75173476e-03,\n",
       "        -6.11886615e-03,  5.23168594e-03, -2.16155755e-03,  3.87321197e-04,\n",
       "         2.18928093e-03,  4.72594099e-03, -2.09198962e-03, -4.99509089e-03,\n",
       "         3.47782462e-03, -2.64818291e-03,  7.65207736e-03,  5.39976572e-05,\n",
       "         3.45773436e-03,  1.03091435e-04, -1.71086041e-03,  5.21488162e-03,\n",
       "        -5.95576363e-03,  1.11991214e-03,  3.10756336e-03, -1.02029706e-03,\n",
       "         3.35448585e-03, -7.44565343e-03,  3.33314016e-03, -1.80508057e-03,\n",
       "         3.99204670e-03,  1.22132897e-03,  2.93701049e-03,  1.97699131e-03,\n",
       "         2.55030263e-05, -2.93703680e-03, -9.21342056e-03,  1.43100217e-03,\n",
       "         1.02103793e-03,  2.28402554e-04,  5.60272194e-04,  2.75838166e-03,\n",
       "         3.74892238e-03,  1.30108034e-03,  1.22886931e-03, -2.22318035e-04,\n",
       "         1.87158759e-03, -6.00023595e-05,  2.05679471e-03, -1.13257533e-03,\n",
       "         1.27681810e-03, -3.11023672e-03, -1.76095497e-03,  3.53520736e-03,\n",
       "        -1.75408635e-03, -8.78516119e-04, -2.08648038e-03, -4.01073415e-03,\n",
       "        -4.36847942e-04,  2.28697038e-03,  5.62020391e-03,  2.97101401e-03,\n",
       "         7.61847477e-05,  5.98952919e-03, -1.29858975e-03,  1.84374454e-03,\n",
       "         2.95502803e-04,  2.44454801e-04,  2.20007612e-03,  2.54129962e-04,\n",
       "        -6.72633760e-04,  1.82156463e-03,  3.36475600e-03, -7.32196448e-03,\n",
       "        -6.07827492e-03, -3.28197930e-04,  4.40305518e-03, -7.23543286e-04,\n",
       "        -3.80802783e-03, -2.78144027e-03,  4.80748201e-03, -4.23035724e-03,\n",
       "        -3.24775768e-03, -9.15064476e-04,  1.95195351e-03, -2.03317124e-03,\n",
       "         3.65038472e-03, -3.96574661e-03,  3.18114622e-03, -1.07294880e-04,\n",
       "         8.79725732e-04, -1.53806212e-03, -2.60714837e-03,  4.63728653e-03],\n",
       "       dtype=float32),\n",
       " array([-5.7995315e-03,  4.4005080e-03,  3.3651907e-03,  4.2613116e-03,\n",
       "         9.2253304e-04, -5.7932665e-03,  3.4358669e-03,  7.3200786e-03,\n",
       "        -5.9668423e-04, -5.8158967e-03,  5.4508769e-03, -1.7435373e-03,\n",
       "        -2.0568350e-03,  2.4716950e-03,  2.3174530e-03,  1.0864957e-03,\n",
       "         6.1673387e-03,  1.0535377e-03, -6.7345961e-03, -1.0620216e-03,\n",
       "         3.7771116e-03, -5.4909306e-04,  8.2200086e-03,  1.3285212e-04,\n",
       "         1.1138282e-03,  6.7142653e-04,  9.2486465e-05,  4.6797390e-03,\n",
       "        -2.4128084e-03,  1.0685941e-03,  1.0422996e-03, -3.0377072e-03,\n",
       "         5.9951021e-04, -5.0345589e-03,  1.8136505e-03,  3.2225230e-03,\n",
       "         8.0758883e-03, -1.9352456e-03,  6.0329461e-05,  4.7613536e-03,\n",
       "         5.7476730e-04,  1.0613020e-03, -3.8777019e-03, -2.5172802e-03,\n",
       "         1.3959208e-03,  3.4761357e-03,  3.8277949e-04,  1.8962369e-03,\n",
       "         1.1215905e-03,  2.8843472e-03,  1.3120301e-03, -1.6461100e-03,\n",
       "        -4.6422952e-03, -1.7906037e-03,  4.7048461e-04,  1.2636752e-03,\n",
       "         5.1752334e-03,  3.0605046e-03,  4.4141375e-04,  4.2727385e-03,\n",
       "        -3.2778904e-03,  2.8309457e-03, -3.6010580e-04, -4.6386220e-03,\n",
       "         2.1350102e-03,  6.7525153e-04,  2.0257656e-03,  2.6224020e-03,\n",
       "         7.7677291e-04, -2.5929790e-04,  2.5084179e-03, -1.4431704e-03,\n",
       "         9.2028471e-04,  2.4273768e-03,  4.4221725e-04, -3.6317119e-03,\n",
       "        -1.6578013e-03,  1.2235156e-03, -1.0680107e-03, -3.4348611e-03,\n",
       "        -5.1607587e-03,  4.2580054e-03,  4.8810714e-03,  1.0768159e-03,\n",
       "        -1.9952154e-03, -9.8737364e-04,  5.0354009e-03, -3.1552620e-03,\n",
       "        -8.5925852e-04, -2.4742624e-03, -1.5689767e-03, -8.1668299e-04,\n",
       "         1.6251210e-03, -3.4089026e-03,  5.5281208e-03,  2.4217607e-03,\n",
       "         7.6768425e-04, -5.6268875e-03, -3.7049039e-03,  1.7828498e-03],\n",
       "       dtype=float32),\n",
       " array([-3.0204505e-03,  2.3264962e-03,  1.1601960e-03,  4.4585820e-03,\n",
       "         1.9441830e-03, -1.9793583e-03,  1.2970631e-03,  5.8876574e-03,\n",
       "        -5.3908695e-03, -1.2438027e-03,  7.7765313e-04, -4.3555088e-03,\n",
       "        -2.7508973e-04,  4.8439917e-03,  1.9943607e-03, -2.2147025e-04,\n",
       "         4.9457778e-03,  6.1484794e-03, -6.8439203e-03, -5.0487719e-03,\n",
       "         8.6510181e-04, -1.4371405e-03,  3.7892871e-03, -5.8771656e-03,\n",
       "         7.0237126e-03, -1.7782957e-03,  8.4812683e-04,  5.1431102e-03,\n",
       "        -5.2704127e-03,  2.2443840e-03,  2.6411389e-03, -4.2396737e-03,\n",
       "         5.1102042e-04, -5.1633450e-03, -2.3695573e-03, -2.4422887e-04,\n",
       "         4.8550270e-03,  1.1566281e-03,  3.6751798e-03,  1.2127539e-03,\n",
       "        -2.4331801e-03, -8.3948486e-05, -6.2709409e-03,  6.8203761e-04,\n",
       "         2.7954980e-04,  4.0425356e-03, -9.6119940e-05,  1.7897417e-03,\n",
       "         7.0873619e-04,  3.3303697e-03,  3.6556055e-04, -2.5534655e-03,\n",
       "        -3.8054634e-03, -1.1705247e-03, -5.2071299e-04, -6.7185797e-04,\n",
       "         3.8936196e-03, -1.5247749e-03, -3.5735935e-03,  4.4638631e-03,\n",
       "        -1.9409428e-03, -7.0188398e-05, -1.3348398e-04, -3.7458830e-03,\n",
       "        -1.7202366e-03,  5.7579777e-03,  4.8375665e-03,  1.7534791e-03,\n",
       "        -7.1948726e-04,  4.9027465e-03,  1.9183625e-03,  1.5952270e-03,\n",
       "         2.7465429e-03, -2.5287768e-04,  1.3761332e-04,  7.3859142e-04,\n",
       "         3.3227212e-03,  1.6075336e-04, -1.1071842e-04, -4.1370397e-03,\n",
       "        -3.0025996e-03, -6.0167396e-04,  6.8732089e-04,  1.3102575e-04,\n",
       "        -1.0857586e-03, -1.9864792e-03,  4.6266444e-04, -7.3425448e-03,\n",
       "         2.6377868e-03,  7.2294025e-04, -5.9675885e-04,  1.4384659e-03,\n",
       "         4.9501085e-03, -3.9212233e-03,  4.9554412e-03,  4.3664123e-03,\n",
       "         7.6947146e-04, -2.9734951e-03, -1.3185141e-04,  1.2931240e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_matrix # Matriz de embeddings senteces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 5 # Número máximo de palavras em uma sentença\n",
    "embedding_size = 10 # Tamanho do vetor a ser gerado em uma embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'Primeira': 2,\n",
       " 'Pergunta': 3,\n",
       " 'Dia': 4,\n",
       " 'Segunda': 5,\n",
       " 'Terceira': 6,\n",
       " 'Quarta': 7}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um dicionário de palavras e seus índices correspondentes:\n",
    "\n",
    "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}  # adicionando tokens especiais para padding e desconhecido\n",
    "for sentence in corpus:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "            \n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 0, 0], [5, 3, 4, 0, 0], [6, 3, 4, 0, 0], [7, 3, 4, 0, 0]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma lista de indices para cada sentença\n",
    "# Se a sentença não tiver a palavra, preencher com zeros a direita até\n",
    "# todas as listas terem o mesmo tamanho\n",
    "indexed_sentences = []\n",
    "for sentence in corpus:\n",
    "    indexed_sentence = [word2idx.get(word, word2idx[\"<UNK>\"]) for word in sentence]\n",
    "    indexed_sentence += [word2idx[\"<PAD>\"]] * (max_seq_length - len(indexed_sentence))\n",
    "    indexed_sentences.append(indexed_sentence)\n",
    "    \n",
    "indexed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_sentences_tensor = torch.tensor(indexed_sentences, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (tamanho do vocab, tamanho da emb de saida, index referente ao padding)\n",
    "embedding_layer = nn.Embedding(len(word2idx), embedding_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6438,  0.9252, -1.5696, -0.4842, -0.4853,  0.4907,  0.9502,\n",
       "           0.0519, -0.9888, -1.2807],\n",
       "         [ 0.8546, -0.6612, -0.8398, -0.6380, -0.6011,  0.6486, -0.7704,\n",
       "          -0.6828,  0.2890,  0.7763],\n",
       "         [ 1.2898, -0.5775,  0.1939, -1.0228, -0.7897, -1.3141, -2.4340,\n",
       "          -0.1878, -1.0832, -0.7687],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1566,  1.4703,  0.0842,  0.0208,  1.0347, -0.0311,  0.2105,\n",
       "          -1.0327, -1.1158, -0.5674],\n",
       "         [ 0.8546, -0.6612, -0.8398, -0.6380, -0.6011,  0.6486, -0.7704,\n",
       "          -0.6828,  0.2890,  0.7763],\n",
       "         [ 1.2898, -0.5775,  0.1939, -1.0228, -0.7897, -1.3141, -2.4340,\n",
       "          -0.1878, -1.0832, -0.7687],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.8076,  1.3981, -1.3864,  1.1689, -0.7025, -0.1566,  0.7677,\n",
       "          -0.6316, -0.8778, -0.1585],\n",
       "         [ 0.8546, -0.6612, -0.8398, -0.6380, -0.6011,  0.6486, -0.7704,\n",
       "          -0.6828,  0.2890,  0.7763],\n",
       "         [ 1.2898, -0.5775,  0.1939, -1.0228, -0.7897, -1.3141, -2.4340,\n",
       "          -0.1878, -1.0832, -0.7687],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.5434,  0.2136, -0.9881,  0.6947,  1.3034, -1.1082,  1.7522,\n",
       "          -0.1781, -1.1036, -0.3900],\n",
       "         [ 0.8546, -0.6612, -0.8398, -0.6380, -0.6011,  0.6486, -0.7704,\n",
       "          -0.6828,  0.2890,  0.7763],\n",
       "         [ 1.2898, -0.5775,  0.1939, -1.0228, -0.7897, -1.3141, -2.4340,\n",
       "          -0.1878, -1.0832, -0.7687],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = embedding_layer(indexed_sentences_tensor)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 10])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (batch_size, num_palavras, embedding_size)\n",
    "embedded_sentences.shape\n",
    "# num_palavras - Número total de palavras por sentença\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**batch_size** representa o número de exemplos (amostras) de treinamento que serão usados em cada iteração (ou batch) do treinamento da rede neural. Por exemplo, se você tiver 1000 exemplos de treinamento e definir um batch_size de 32, a rede neural processará 32 exemplos de treinamento de cada vez e levará 1000/32 iterações para concluir uma época de treinamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_palavras** representa o número de palavras em cada exemplo (amostra) de treinamento. Em tarefas de NLP, cada exemplo geralmente é uma sentença, e o **num_palavras** é o número de palavras nessa sentença. Por exemplo, a sentença \"O gato está em cima da mesa\" tem num_palavras = 7. Em tarefas de NLP, é comum limitar o **num_palavras** a um valor fixo para simplificar o processamento da rede neural. Isso é conhecido como padding ou truncating e é útil para garantir que todas as entradas tenham o mesmo tamanho, o que facilita o processamento em lotes (batches) de exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = embedded_sentences.shape[0]\n",
    "num_words = embedded_sentences.shape[1]\n",
    "embedding_size = embedded_sentences.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma dimensão para os canais\n",
    "embedded_sentences = embedded_sentences.unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 10, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**in_channels** é o número de canais (ou mapas de características) na entrada da camada convolucional. Em outras palavras, é o número de \"planos\" de dados que a camada convolucional espera receber como entrada. Por exemplo, se a camada convolucional recebe uma imagem colorida como entrada, in_channels seria 3, correspondendo aos canais de vermelho, verde e azul."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**out_channels** é o número de filtros de convolução que a camada convolucional deve gerar. Cada filtro é aplicado a cada canal da entrada, produzindo um mapa de características (ou canal) na saída. Em outras palavras, out_channels é o número de \"planos\" de dados que a camada convolucional deve produzir na saída. Cada mapa de características representa um conjunto diferente de características extraídas da entrada, como bordas, texturas ou padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configurando a saída de uma camada de Embedding com a entrada da Convolucional:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in_channels = embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(5, 32, (5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 6, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a Conv\n",
    "output = conv(embedded_sentences)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 6, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a Conv com uma função de ativação\n",
    "u_features = F.relu(conv(embedded_sentences))\n",
    "u_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4 é o tamanho do lote (batch_size)\n",
    "- 32 é o número de mapas de características de saída (out_channels)\n",
    "- 6 é o tamanho da sequência de recursos (sequence length)\n",
    "- 1 é o número de canais (in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando uma max Polling\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "maxpool = nn.MaxPool1d(kernel_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_features = maxpool(u_features.squeeze(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_sequence_length = int((u_features.shape[2] - kernel_size) / stride) + 1\n",
    "pooled_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 5])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# achatar a saída da camada de max pooling em um tensor unidimensional\n",
    "flattened_output = torch.flatten(u_features, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar uma camada totalmente conectada com 128 neurônios de saída\n",
    "fc_layer = nn.Linear(flattened_output.shape[1], 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar a camada totalmente conectada na saída achata da camada de max pooling\n",
    "fc_output = fc_layer(flattened_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando um dropout na camada linear\n",
    "dropout = nn.Dropout(0.5)\n",
    "u_features = dropout(fc_layer(flattened_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1299,  0.0000, -0.4641,  0.0140, -0.0000,  0.0901, -0.0000,  0.5400,\n",
       "          0.0103,  0.6224, -0.1563, -0.3168,  0.0000, -0.0000, -0.1686,  0.4317,\n",
       "          0.6308, -0.3785,  0.0000, -0.0068, -0.0000,  0.3081, -0.0000, -0.2691,\n",
       "         -0.1095, -0.0000, -0.2887, -0.3964, -0.4780, -0.0000, -0.3941, -0.0842,\n",
       "         -0.0000,  0.0000,  0.8834,  0.4940,  0.1893,  0.0000, -0.0000,  0.4273,\n",
       "         -0.2535, -0.0000, -0.2096, -0.0000, -0.2713, -0.0000, -0.1481,  0.6080,\n",
       "          0.1316,  0.0000,  0.7323,  0.0701, -0.0000,  0.0000,  1.0627,  0.0000,\n",
       "         -0.0000, -0.0343,  0.0000, -0.0000, -0.4673,  0.0426,  0.0000, -0.0000,\n",
       "         -0.5131, -0.0000, -0.2281, -0.0000,  0.0315,  0.0000, -0.1138, -0.2760,\n",
       "          0.0000, -0.1161,  0.0000, -0.3690,  0.3451, -0.0313,  0.0000, -0.1170,\n",
       "         -0.0000, -0.1781,  0.0870, -0.0000, -0.0000, -0.1570, -0.0000, -0.7528,\n",
       "          0.0000, -0.0000, -1.0736,  0.2810,  0.0000,  0.5754,  0.0000,  0.3562,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.4020,  0.4115, -0.7128, -0.3026,\n",
       "         -0.0000,  0.5823, -0.4690, -0.0000, -0.0132,  0.0000,  0.0000, -0.4248,\n",
       "         -0.1771,  0.0000, -0.3031,  0.1711, -0.0000,  0.4451, -0.2387, -0.7825,\n",
       "         -0.6903, -0.0000,  1.6103,  0.0000, -0.3175,  0.3340,  0.0000, -0.5831],\n",
       "        [-0.2679,  0.3853, -0.5169, -0.0306, -0.0000,  0.2306, -0.0000,  0.5743,\n",
       "         -0.0000,  0.0000, -0.1461, -0.7281,  0.6641, -0.9351, -0.0000,  0.4215,\n",
       "          0.0000, -0.4207,  0.4977, -0.1804, -0.6136,  0.0000, -0.2244, -0.0000,\n",
       "         -0.0000, -0.0000, -0.4335, -0.4395, -0.0000, -0.6911, -0.0000,  0.0000,\n",
       "         -1.0817, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.3318, -0.0000, -0.0000, -0.0000, -0.2538, -0.0000,  0.6231,\n",
       "          0.0000,  0.0000,  0.0000,  0.3641,  0.0000,  0.1952,  0.0000,  0.2496,\n",
       "         -0.0000, -0.0130,  0.0000, -0.2324, -0.3205,  0.1335,  0.0000, -0.2685,\n",
       "         -0.7223, -0.2554, -0.0000, -0.0000,  0.0000,  0.2484, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.2419, -0.0000,  0.0367,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000, -0.7948, -0.0449, -0.5807, -0.0000,\n",
       "          0.0000, -0.2070, -0.0000,  0.0000, -0.2815,  0.3037, -0.1541,  0.2642,\n",
       "         -0.6596, -0.5683, -0.4949,  0.2913, -0.5894,  0.0000, -0.6302,  0.0555,\n",
       "          0.0000,  0.4931, -0.5099, -0.0707, -0.1313,  0.0000,  1.0660, -0.2981,\n",
       "          0.0000,  0.1306, -0.0000,  0.0000, -0.5125,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.4766, -0.6619, -0.0000,  0.9026, -0.3974],\n",
       "        [-0.0000,  0.0000, -0.2347, -0.2283, -0.0000, -0.0000, -0.0769,  0.0000,\n",
       "          0.0000,  0.0000, -0.1686, -0.0000,  0.9006, -1.0158, -0.0000,  0.0000,\n",
       "          0.0000, -0.4339,  0.5035, -0.2929, -0.6127,  0.0000, -0.5401, -0.3512,\n",
       "         -0.1136, -0.0000, -0.0000, -0.3076, -0.0000, -0.5835, -0.1672,  0.0222,\n",
       "         -1.1401, -0.0000,  0.0000,  0.0000,  0.5226,  0.6229, -0.2940,  0.3068,\n",
       "         -0.2271, -0.3205, -0.4356, -0.0000, -0.0000, -0.0000, -0.6844,  0.7019,\n",
       "          0.0000,  0.0000,  0.0000,  0.1491,  0.0506,  0.3353,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0242, -0.5165,  0.1611,  0.2863,  0.1122,\n",
       "         -0.9160, -0.0000, -0.2993,  0.0095, -0.0000,  0.2493, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.5792, -0.1968,  0.0279,  0.0321,  0.0000, -0.0000,\n",
       "         -0.2224, -0.3517, -0.2650, -0.0000, -1.1548, -0.0000, -0.0000, -0.8358,\n",
       "          0.0000, -0.2093, -0.8910, -0.0000,  0.0000,  0.5759, -0.2157,  0.0000,\n",
       "         -0.9868, -0.5218,  0.0000,  0.3691, -0.7968,  0.5341, -0.9785, -0.0000,\n",
       "          0.1474,  0.0000, -0.0000, -0.2145,  0.0200,  0.0000,  0.0000, -0.5802,\n",
       "         -0.0723,  0.3980, -0.3464,  0.0000, -0.0000,  0.0000, -0.0000, -0.4053,\n",
       "         -0.8020, -0.2210,  0.0000,  0.6008, -0.0000,  0.0000,  1.1555, -0.0000],\n",
       "        [-0.3854,  0.0000, -0.0000, -0.1470, -0.0000, -0.0000, -0.0000,  0.5619,\n",
       "          0.2358,  0.0000, -0.2178, -0.0000,  0.0000, -0.6914,  0.0000,  0.0000,\n",
       "          0.0000, -0.5137,  0.6085, -0.0000, -0.0000,  0.2857, -0.3932, -0.0000,\n",
       "          0.0000, -0.3296, -0.0000, -0.0000, -0.7242, -0.7646, -0.4249,  0.2130,\n",
       "         -0.8378, -0.0000,  0.0000,  0.0000,  0.5540,  0.0000, -0.2213,  0.0000,\n",
       "          0.0000, -0.4992, -0.0000, -0.0000, -0.0000, -0.3026, -0.0000,  0.0000,\n",
       "          0.0000,  0.0120,  0.0000,  0.0194, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.1368,  0.3036, -0.0000,\n",
       "         -0.9651, -0.0000, -0.0000,  0.2755, -0.0000,  0.2592, -0.0000, -0.0000,\n",
       "          0.4445, -0.0000,  0.8613,  0.4784,  0.0000,  0.2869,  0.0000,  0.3626,\n",
       "         -0.0000,  0.0435, -0.0000, -0.0000, -0.0000, -0.0000, -0.7987, -0.7247,\n",
       "          0.3198, -0.0000, -0.0000, -0.0740,  0.1724,  0.4172,  0.0000,  0.0000,\n",
       "         -0.0000, -0.8071, -0.0000,  0.0000, -0.0000,  0.0000, -0.7016,  0.0092,\n",
       "          0.0652,  0.2482, -0.4096, -0.1777, -0.0455,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.2333, -0.5608, -0.0000, -0.0000,  0.0000, -0.1799,  0.0000,\n",
       "         -0.9329, -0.1567,  0.0000,  0.0000, -0.5539,  0.0000,  0.0000, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uma rede convolucional com camada de embedding, convolução, max pooling e totalmente conectada pode ser usada para representar os comentários de um usuário em um espaço de características (ou features) e, em seguida, combinar essas representações em uma única representação que descreva o usuário como um todo.\n",
    "\n",
    "\n",
    "- Camada de embedding: essa camada é responsável por transformar as palavras em vetores de tamanho fixo, que podem ser processados por camadas convolucionais. Cada palavra é mapeada para um vetor denso de tamanho fixo, de tal forma que palavras semanticamente similares são mapeadas para vetores que também são semanticamente similares. Esses vetores de palavras são usados como entrada para a próxima camada.\n",
    "\n",
    "- Camadas convolucionais: essas camadas usam filtros para extrair informações relevantes das representações de palavras geradas pela camada de embedding. Cada filtro é uma matriz de pesos que é aplicada a um trecho da representação de entrada, e o resultado é uma ativação que representa a presença de uma determinada característica nessa parte da entrada. Diferentes filtros podem ser usados para detectar diferentes tipos de características, como padrões de palavras específicas ou n-gramas.\n",
    "\n",
    "- Camadas de max pooling: essas camadas reduzem a dimensionalidade da saída das camadas convolucionais, selecionando o valor máximo em cada janela deslizante da representação da entrada. Isso é feito para identificar as características mais importantes em cada trecho da entrada.\n",
    "\n",
    "- Camada totalmente conectada: a saída da camada de max pooling é achata para uma dimensão unidimensional e passada para uma camada totalmente conectada, que combina as características extraídas de todas as janelas em uma única representação do usuário. Essa camada pode ter várias unidades de saída, dependendo do tamanho do espaço de características desejado.\n",
    "\n",
    "##### A saída final da rede é uma representação do usuário em um espaço de características. Essas características podem ser usadas para vários fins, como classificar usuários por interesse ou prever a probabilidade de que eles tomem uma determinada ação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
